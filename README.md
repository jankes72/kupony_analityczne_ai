# Kupony Analityczne AI

## Opis projektu

Projekt to eksperyment badawczy nad modelami predykcyjnymi dla zdarzeÅ„ sportowych zintegrowanymi z
instalacjÄ… danych i API. System Å‚Ä…czy:

- eksperymenty z rÃ³Å¼nymi architekturami sieci neuronowych do predykcji wynikÃ³w,
- moduÅ‚ integrujÄ…cy z zewnÄ™trznym API (API-Sports) do zbierania danych meczowych (`app/sport_wrapper.py`),
- warstwÄ™ przechowywania i transformacji danych (SQLite -> Parquet) oraz narzÄ™dzia do feature engineering,
- serwer HTTP oparty na FastAPI z endpointami do monitoringu, pobierania danych, budowania datasetÃ³w i testÃ³w.

CaÅ‚oÅ›Ä‡ pozwala na: zasysanie danych, tworzenie feature'Ã³w, budowÄ™ datasetÃ³w Parquet i szybkÄ… ocenÄ™ modeli.

## Charakterystyka

- ğŸ§­ Integracja z API-Sports (wrapper `ApiSportsHockey`) â€” pobieranie lig, meczÃ³w, eventÃ³w, standings,
- ğŸ—„ï¸ Lokalna baza SQLite do przechowywania zasysanych meczÃ³w (`hockey.sqlite`),
- ğŸ“¦ Eksport datasetÃ³w do Parquet z gotowymi cechami (`nhl_2023.parquet` przykÅ‚adowy plik),
- âš¡ FastAPI z endpointami: zdrowie, statystyki, monitoring systemu, endpointy operacyjne (`collect-world-data`, `fetch-and-store-season`, `build-dataset`),
- ğŸ§© Helpery do feature-engineering (`app/features_helpers.py`) â€” budowa targetÃ³w, normalizacja kursÃ³w, cechy formy i H2H,
- ğŸ› ï¸ CLI w `app/sport_wrapper.py` do szybkich testÃ³w (pobieranie lig, fetch, budowa datasetu),
- ğŸ“š Interaktywna dokumentacja OpenAPI dostÄ™pna pod `/docs` i `/redoc`.

## Wymagania

- Python 3.8+
- pip
- ZaleÅ¼noÅ›ci w `requirements.txt` (FastAPI, Uvicorn, pandas, requests, psutil, pydantic, itp.).

## Instalacja

1. Klonuj repozytorium
```bash
git clone https://github.com/jankes72/kupony_analityczne_ai.git
cd kupony_analityczne_ai
```

2. Zainstaluj zaleÅ¼noÅ›ci
```bash
pip install -r requirements.txt
```

## Uruchomienie

```bash
python run.py
```

Serwer uruchomi siÄ™ na `http://localhost:8000`.

## API Endpoints (szybki przeglÄ…d)

- `GET /` â€” informacje o API i lista endpointÃ³w
- `GET /health` â€” health-check
- `GET /stats` â€” przykÅ‚adowe statystyki aplikacji
- `GET /monitor` â€” metryki systemowe (CPU, pamiÄ™Ä‡, uptime)
- `GET /settings` â€” zwraca statyczne ustawienia
- `POST /collect-world-data` â€” uniwersalny proxy do `ApiSportsHockey`
- `POST /fetch-and-store-season` â€” zasysa mecze dla podanego `league`+`season` i zapisuje do SQLite
- `POST /build-dataset` â€” buduje dataset Parquet z danych w SQLite (feature engineering)

SzczegÃ³Å‚owe kontrakty request/response znajdujÄ… siÄ™ niÅ¼ej oraz w automatycznie wygenerowanej dokumentacji OpenAPI.

## Kontrakty endpointÃ³w (request / response)

### POST /collect-world-data

Request JSON (przykÅ‚ad):

```json
{
	"sports": {
		"api_key": "API_SPORTS_KEY",
		"action": "leagues|games|game|games_events|team_statistics",
		"params": { "league": 57, "season": 2024 }
	}
}
```

Response (przykÅ‚ad, zaleÅ¼y od akcji):

```json
{
	"result": [ /* array lub obiekt zwrÃ³cony przez ApiSports */ ]
}
```

### POST /fetch-and-store-season

Request JSON:

```json
{
	"api_key": "API_SPORTS_KEY",
	"league": 57,
	"season": 2024,
	"db_path": "./hockey.sqlite"
}
```

Response (przykÅ‚ad):

```json
{
	"ok": true,
	"summary": {
		"league": 57,
		"season": 2024,
		"fetched": 123,
		"db_path": "./hockey.sqlite"
	}
}
```

### POST /build-dataset

Request JSON:

```json
{
	"league": 57,
	"season": 2024,
	"db_path": "./hockey.sqlite",
	"output_path": "./nhl_2024.parquet",
	"return_file": false
}
```

Response (przykÅ‚ady):

- Gdy `return_file` = `false`:

```json
{
	"ok": true,
	"parquet_path": "dataset_hockey_league57_season2024.parquet"
}
```

- Gdy `return_file` = `true` â€” endpoint zwraca plik Parquet jako download (`Content-Disposition`).

Uwagi: w przypadku bÅ‚Ä™dÃ³w endpointy zwracajÄ… odpowiednie kody HTTP i pole `detail` z opisem.

## Struktura projektu

```
kupony_analityczne_ai/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # GÅ‚Ã³wna aplikacja FastAPI (endpointy i modele Pydantic)
â”‚   â”œâ”€â”€ sport_wrapper.py     # Wrapper ApiSportsHockey, DB helpers, dataset builder i CLI
+â”‚   â”œâ”€â”€ features_helpers.py  # Feature engineering helpers i GameRow dataclass
+â”‚   â””â”€â”€ README.md            # Dokumentacja moduÅ‚Ã³w wewnÄ…trz `app/`
â”œâ”€â”€ run.py                   # Entry point uruchamiajÄ…cy Uvicorn
â”œâ”€â”€ requirements.txt         # ZaleÅ¼noÅ›ci
â”œâ”€â”€ .env.example             # PrzykÅ‚ad zmiennych Å›rodowiskowych
â”œâ”€â”€ hockey.sqlite            # (opcjonalnie) przykÅ‚adowa baza danych SQLite
â””â”€â”€ nhl_2023.parquet         # (opcjonalnie) przykÅ‚adowy dataset Parquet
```

## Zmienne Å›rodowiskowe

Skopiuj `.env.example` na `.env` i dostosuj wartoÅ›ci:

```
DEBUG=True
HOST=0.0.0.0
PORT=8000
```

## Licencja

MIT

## UÅ¼ycie wytrenowanego modelu (szybka Å›ciÄ…ga)

Po uruchomieniu `app/example.py` w katalogu `models/` pojawiÄ… siÄ™ przykÅ‚adowe zapisy modeli:

- TensorFlow: `models/tf_demo_model/` (katalog z zapisanym modelem Keras)
- PyTorch: `models/torch_demo_model.pt` (pliki wag sieci)

KrÃ³tki przykÅ‚ad uÅ¼ycia (TensorFlow):

```python
import tensorflow as tf
model = tf.keras.models.load_model("models/tf_demo_model")
X_new = ...  # numpy array z cechami w tej samej kolejnoÅ›ci co FEATURE_COLS
pred = model.predict(X_new)
```

Dla PyTorch:

```python
import torch
from app.example import build_torch_model
model = build_torch_model(input_dim=3, n_classes=1)
model.load_state_dict(torch.load("models/torch_demo_model.pt"))
model.eval()
X_new = torch.tensor([[...]], dtype=torch.float32)
with torch.no_grad():
	out = model(X_new)
	prob = torch.sigmoid(out).item()
```

Uwaga: wejÅ›cie musi mieÄ‡ tÄ™ samÄ… kolejnoÅ›Ä‡ i skalowanie cech co podczas treningu. Zapisz `FEATURE_COLS` i uÅ¼ywaj go wszÄ™dzie.
